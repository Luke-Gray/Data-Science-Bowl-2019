{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy import stats\n",
    "import json\n",
    "\n",
    "#Visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#modeling packages\n",
    "from catboost import CatBoostClassifier\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "# spec = pd.read_csv('specs.csv', index_col=0)\n",
    "train_labels = pd.read_csv('train_labels.csv', index_col=0)\n",
    "test = pd.read_csv('test_fin.csv', index_col=0)\n",
    "# new_train = pd.read_csv('new_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2955.79 MB\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        elif 'datetime' not in col_type.name:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "   \n",
    "    return df\n",
    "\n",
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')\n",
    "test.to_csv('test_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = pd.read_csv('train_labels.csv', index_col=0)\n",
    "# train = pd.read_csv('train_encoded.csv', index_col=0)\n",
    "# test = pd.read_csv('test_encoded.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_pickle('train_reduced.pkl')\n",
    "# test = pd.read_pickle('test_reduced.pkl')\n",
    "# train_labels = pd.read_csv('train_labels.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''creating a feature determining whether or not a user\n",
    "cleared an assessment or not, based on the event code information\n",
    "given to us in the competition'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define cleared or not cleared\n",
    "# \n",
    "train['cleared'] = True\n",
    "train.loc[train['event_data'].str.contains('false') & train['event_code'].isin([4100, 4110]), 'cleared'] = False\n",
    "\n",
    "test['cleared'] = True\n",
    "test.loc[test['event_data'].str.contains('false') & test['event_code'].isin([4100, 4110]), 'cleared'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1: accumulated activities per user (installation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def qwk(act,pred,n=4,hist_range=(0,3)):\n",
    "    \n",
    "    O = confusion_matrix(act,pred)\n",
    "    O = np.divide(O,np.sum(O))\n",
    "    \n",
    "    W = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            W[i][j] = ((i-j)**2)/((n-1)**2)\n",
    "            \n",
    "    act_hist = np.histogram(act,bins=n,range=hist_range)[0]\n",
    "    prd_hist = np.histogram(pred,bins=n,range=hist_range)[0]\n",
    "    \n",
    "    E = np.outer(act_hist,prd_hist)\n",
    "    E = np.divide(E,np.sum(E))\n",
    "    \n",
    "    num = np.sum(np.multiply(W,O))\n",
    "    den = np.sum(np.multiply(W,E))\n",
    "        \n",
    "    return 1-np.divide(num,den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''encoding game titles'''\n",
    "\n",
    "list_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\n",
    "activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "\n",
    "# train['title'] = train['title'].map(activities_map)\n",
    "# test['title'] = test['title'].map(activities_map)\n",
    "# train_labels['title'] = train_labels['title'].map(activities_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "win_code[activities_map['Bird Measurer (Assessment)']] = 4110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(user_sample, test_set=False):\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy=0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0 \n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    durations = []\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        if test_set == True:\n",
    "            second_condition = True\n",
    "        else:\n",
    "            if len(session)>1:\n",
    "                second_condition = True\n",
    "            else:\n",
    "                second_condition= False\n",
    "        if (session_type == 'Assessment') & (second_condition):\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            features = user_activities_count.copy()\n",
    "    #         features['installation_id'] = session['installation_id'].iloc[0]\n",
    "#             features['game_session'] = i\n",
    "            features['session_title'] = session['title'].iloc[0] \n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "\n",
    "            features.update(accuracy_groups)\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            if test_set == True:\n",
    "                all_assessments.append(features)\n",
    "            else:\n",
    "                if true_attempts+false_attempts > 0:\n",
    "                    all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "\n",
    "    #         break\n",
    "\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "\n",
    "    if test_set:\n",
    "        return all_assessments[-1] \n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 7: given 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9cb8514a7217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcompiled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mins_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_sample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'installation_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcompiled_data\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0muser_sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m   2016\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2018\u001b[1;33m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2020\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[1;34m(left, right, axis)\u001b[0m\n\u001b[0;32m   1983\u001b[0m           not isinstance(right, (ABCSeries, ABCDataFrame))):\n\u001b[0;32m   1984\u001b[0m         \u001b[1;31m# GH17901\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1985\u001b[1;33m         \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1987\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mto_series\u001b[1;34m(right)\u001b[0m\n\u001b[0;32m   1945\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m                 raise ValueError(msg.format(req_len=len(left.columns),\n\u001b[1;32m-> 1947\u001b[1;33m                                             given_len=len(right)))\n\u001b[0m\u001b[0;32m   1948\u001b[0m             \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to Series, length must be 7: given 0"
     ]
    }
   ],
   "source": [
    "compiled_data = []\n",
    "for i, (ins_id, user_sample) in enumerate(trains.groupby('installation_id', sort=False)):\n",
    "    compiled_data += user_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\n",
    "cat_features = ['session_title']\n",
    "X, y = new_train[all_features], new_train['accuracy_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier():\n",
    "    clf = CatBoostClassifier(\n",
    "                               loss_function='MultiClass',\n",
    "    #                            eval_metric=\"AUC\",\n",
    "                               task_type=\"CPU\",\n",
    "                               learning_rate=0.01,\n",
    "                               iterations=2000,\n",
    "                               od_type=\"Iter\",\n",
    "#                                depth=8,\n",
    "                               early_stopping_rounds=500,\n",
    "    #                            l2_leaf_reg=1,\n",
    "    #                            border_count=96,\n",
    "                               random_seed=2019\n",
    "                              )\n",
    "        \n",
    "    return clf\n",
    "oof = np.zeros(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1\n",
      "0:\tlearn: 1.3792089\ttest: 1.3792932\tbest: 1.3792932 (0)\ttotal: 234ms\tremaining: 7m 48s\n",
      "500:\tlearn: 1.0048554\ttest: 1.0414856\tbest: 1.0414856 (500)\ttotal: 19.4s\tremaining: 58s\n",
      "1000:\tlearn: 0.9789609\ttest: 1.0372794\tbest: 1.0372794 (1000)\ttotal: 39.6s\tremaining: 39.5s\n",
      "1500:\tlearn: 0.9536591\ttest: 1.0361311\tbest: 1.0361115 (1499)\ttotal: 1m 2s\tremaining: 20.7s\n",
      "1999:\tlearn: 0.9326911\ttest: 1.0365752\tbest: 1.0360566 (1520)\ttotal: 1m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.03605656\n",
      "bestIteration = 1520\n",
      "\n",
      "Shrink model to first 1521 iterations.\n",
      "Fold 1 finished in 0:01:25.656842\n",
      "Training on fold 2\n",
      "0:\tlearn: 1.3790483\ttest: 1.3793715\tbest: 1.3793715 (0)\ttotal: 37.8ms\tremaining: 1m 15s\n",
      "500:\tlearn: 1.0055635\ttest: 1.0443320\tbest: 1.0443320 (500)\ttotal: 19.3s\tremaining: 57.7s\n",
      "1000:\tlearn: 0.9811364\ttest: 1.0366911\tbest: 1.0366911 (1000)\ttotal: 38.8s\tremaining: 38.7s\n",
      "1500:\tlearn: 0.9588217\ttest: 1.0335298\tbest: 1.0335298 (1500)\ttotal: 1m\tremaining: 20s\n",
      "1999:\tlearn: 0.9394033\ttest: 1.0321406\tbest: 1.0321270 (1977)\ttotal: 1m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.032127007\n",
      "bestIteration = 1977\n",
      "\n",
      "Shrink model to first 1978 iterations.\n",
      "Fold 2 finished in 0:01:21.694501\n",
      "Training on fold 3\n",
      "0:\tlearn: 1.3791937\ttest: 1.3791649\tbest: 1.3791649 (0)\ttotal: 43.7ms\tremaining: 1m 27s\n",
      "500:\tlearn: 1.0112590\ttest: 1.0221737\tbest: 1.0221737 (500)\ttotal: 19.6s\tremaining: 58.6s\n",
      "1000:\tlearn: 0.9862471\ttest: 1.0132543\tbest: 1.0132527 (999)\ttotal: 38.9s\tremaining: 38.8s\n",
      "1500:\tlearn: 0.9627240\ttest: 1.0090694\tbest: 1.0090694 (1500)\ttotal: 1m 1s\tremaining: 20.3s\n",
      "1999:\tlearn: 0.9427752\ttest: 1.0068207\tbest: 1.0068195 (1998)\ttotal: 1m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.006819523\n",
      "bestIteration = 1998\n",
      "\n",
      "Shrink model to first 1999 iterations.\n",
      "Fold 3 finished in 0:01:22.882563\n",
      "Training on fold 4\n",
      "0:\tlearn: 1.3793485\ttest: 1.3789237\tbest: 1.3789237 (0)\ttotal: 39.3ms\tremaining: 1m 18s\n",
      "500:\tlearn: 1.0183854\ttest: 0.9975110\tbest: 0.9975110 (500)\ttotal: 18.8s\tremaining: 56.3s\n",
      "1000:\tlearn: 0.9929786\ttest: 0.9893321\tbest: 0.9893194 (993)\ttotal: 37.8s\tremaining: 37.7s\n",
      "1500:\tlearn: 0.9679893\ttest: 0.9855092\tbest: 0.9855092 (1500)\ttotal: 59.1s\tremaining: 19.7s\n",
      "1999:\tlearn: 0.9479400\ttest: 0.9845046\tbest: 0.9844473 (1984)\ttotal: 1m 20s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9844472633\n",
      "bestIteration = 1984\n",
      "\n",
      "Shrink model to first 1985 iterations.\n",
      "Fold 4 finished in 0:01:20.714911\n",
      "Training on fold 5\n",
      "0:\tlearn: 1.3791278\ttest: 1.3792823\tbest: 1.3792823 (0)\ttotal: 35.2ms\tremaining: 1m 10s\n",
      "500:\tlearn: 1.0080282\ttest: 1.0365616\tbest: 1.0365616 (500)\ttotal: 19.2s\tremaining: 57.4s\n",
      "1000:\tlearn: 0.9829211\ttest: 1.0281880\tbest: 1.0281852 (998)\ttotal: 38.9s\tremaining: 38.8s\n",
      "1500:\tlearn: 0.9596794\ttest: 1.0248959\tbest: 1.0248959 (1500)\ttotal: 1m\tremaining: 20s\n",
      "1999:\tlearn: 0.9405219\ttest: 1.0235183\tbest: 1.0235089 (1989)\ttotal: 1m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.023508918\n",
      "bestIteration = 1989\n",
      "\n",
      "Shrink model to first 1990 iterations.\n",
      "Fold 5 finished in 0:01:22.466027\n",
      "------------------------------\n",
      "OOF QWK: 0.5108581479639756\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "# preds = np.zeros(len(X_test))\n",
    "oof = np.zeros(len(X))\n",
    "NFOLDS = 5\n",
    "folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\n",
    "\n",
    "training_start_time = time()\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n",
    "    start_time = time()\n",
    "    print(f'Training on fold {fold+1}')\n",
    "    clf = make_classifier()\n",
    "    clf.fit(X.loc[trn_idx, all_features], y.loc[trn_idx], eval_set=(X.loc[test_idx, all_features], y.loc[test_idx]),\n",
    "                          use_best_model=True, verbose=500)\n",
    "    \n",
    "#     preds += clf.predict(X_test).reshape(len(X_test))/NFOLDS\n",
    "    oof[test_idx] = clf.predict(X.loc[test_idx, all_features]).reshape(len(test_idx))\n",
    "    \n",
    "    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    \n",
    "print('-' * 30)\n",
    "print('OOF QWK:', qwk(y, oof))\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3790183\ttotal: 11.5ms\tremaining: 22.9s\n",
      "500:\tlearn: 1.0083652\ttotal: 4.4s\tremaining: 13.2s\n",
      "1000:\tlearn: 0.9833509\ttotal: 8.89s\tremaining: 8.87s\n",
      "1500:\tlearn: 0.9605747\ttotal: 13.7s\tremaining: 4.54s\n",
      "1999:\tlearn: 0.9418766\ttotal: 18.6s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "clf = make_classifier()\n",
    "clf.fit(X, y, verbose=500)\n",
    "\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8928d66d4d09463a9c563afdc9abbc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# process test set\n",
    "new_test = []\n",
    "for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=1000):\n",
    "    a = get_data(user_sample, test_set=True)\n",
    "    new_test.append(a)\n",
    "    \n",
    "X_test = pd.DataFrame(new_test)\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['accuracy_group'] = np.round(preds).astype('int')\n",
    "submission.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>installation_id</th>\n",
       "      <th>accuracy_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00abaee7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01242218</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>017c5718</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01a44906</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01bc6cb6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  installation_id  accuracy_group\n",
       "0        00abaee7               3\n",
       "1        01242218               3\n",
       "2        017c5718               3\n",
       "3        01a44906               3\n",
       "4        01bc6cb6               3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.reset_index(inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installation_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00abaee7</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01242218</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>017c5718</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01a44906</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01bc6cb6</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy_group\n",
       "installation_id                \n",
       "00abaee7                      3\n",
       "01242218                      3\n",
       "017c5718                      3\n",
       "01a44906                      3\n",
       "01bc6cb6                      3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "samp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2: Using engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e2478a5c064fc79417f5a65f4ed628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'Int64Index' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-e7bf441d9112>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mins_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_sample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'installation_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m17000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mcompiled\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0muser_sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Int64Index' object is not callable"
     ]
    }
   ],
   "source": [
    "compiled = []\n",
    "\n",
    "for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=17000):\n",
    "    if train.index(i) == new_train.index(i):\n",
    "        compiled+=user_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'misses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-90df2194a356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'event_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'misses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#     for key, value in y.items():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#         if type(value)==dict:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'misses'"
     ]
    }
   ],
   "source": [
    "####\n",
    "cnt = 0\n",
    "k = 'misses'\n",
    "for e in range(len(train)):\n",
    "    x = train['event_data'].iloc[e]\n",
    "    y = json.loads(x)\n",
    "    for key, value in y.items():\n",
    "        if type(value)==dict:\n",
    "            for key, val in value.items():\n",
    "                if k in key:\n",
    "                    print(key)\n",
    "            \n",
    "#         if value.str.contains('misses'):\n",
    "#             cnt += y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df: pd.DataFrame, field_name: str,\n",
    "                 prefix: str = None, drop: bool = True, time: bool = True, date: bool = True):\n",
    "    \"\"\"\n",
    "    Helper function that adds columns relevant to a date in the column `field_name` of `df`.\n",
    "    from fastai: https://github.com/fastai/fastai/blob/master/fastai/tabular/transform.py#L55\n",
    "    \"\"\"\n",
    "    field = df[field_name]\n",
    "    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Is_month_end', 'Is_month_start']\n",
    "    if date:\n",
    "        attr.append('Date')\n",
    "    if time:\n",
    "        attr = attr + ['Hour', 'Minute']\n",
    "    for n in attr:\n",
    "        df[prefix + n] = getattr(field.dt, n.lower())\n",
    "    if drop:\n",
    "        df.drop(field_name, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e\n",
    "\n",
    "\n",
    "def eval_qwk_lgb(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    y_pred[y_pred <= 1.12232214] = 0\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.12232214, y_pred <= 1.73925866))] = 1\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.73925866, y_pred <= 2.22506454))] = 2\n",
    "    y_pred[y_pred > 2.22506454] = 3\n",
    "\n",
    "    # y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "\n",
    "class LGBWrapper_regr(object):\n",
    "    \"\"\"\n",
    "    A wrapper for lightgbm model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = lgb.LGBMRegressor()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "        if params['objective'] == 'regression':\n",
    "            eval_metric = eval_qwk_lgb_regr\n",
    "        else:\n",
    "            eval_metric = 'auc'\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        eval_names = ['train']\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "            eval_names.append('valid')\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "            eval_names.append('holdout')\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = 'auto'\n",
    "        else:\n",
    "            categorical_columns = 'auto'\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_metric,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       categorical_feature=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test, num_iteration=self.model.best_iteration_)\n",
    "\n",
    "    \n",
    "def eval_qwk_xgb(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for xgb.\n",
    "    \"\"\"\n",
    "    # print('y_true', y_true)\n",
    "    # print('y_pred', y_pred)\n",
    "    y_true = y_true.get_label()\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    return 'cappa', -qwk(y_true, y_pred)\n",
    "\n",
    "\n",
    "class LGBWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for lightgbm model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = lgb.LGBMClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        eval_names = ['train']\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "            eval_names.append('valid')\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "            eval_names.append('holdout')\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = 'auto'\n",
    "        else:\n",
    "            categorical_columns = 'auto'\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_qwk_lgb,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       categorical_feature=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if self.model.objective == 'binary':\n",
    "            return self.model.predict_proba(X_test, num_iteration=self.model.best_iteration_)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, num_iteration=self.model.best_iteration_)\n",
    "\n",
    "\n",
    "class CatWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for catboost model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = cat.CatBoostClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        self.model = self.model.set_params(**{k: v for k, v in params.items() if k != 'cat_cols'})\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = None\n",
    "        else:\n",
    "            categorical_columns = None\n",
    "        \n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       cat_features=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if 'MultiClass' not in self.model.get_param('loss_function'):\n",
    "            return self.model.predict_proba(X_test, ntree_end=self.model.best_iteration_)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, ntree_end=self.model.best_iteration_)\n",
    "\n",
    "\n",
    "class XGBWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for xgboost model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = xgb.XGBClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_metric=eval_qwk_xgb,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'])\n",
    "\n",
    "        scores = self.model.evals_result()\n",
    "        self.best_score_ = {k: {m: m_v[-1] for m, m_v in v.items()} for k, v in scores.items()}\n",
    "        self.best_score_ = {k: {m: n if m != 'cappa' else -n for m, n in v.items()} for k, v in self.best_score_.items()}\n",
    "\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if self.model.objective == 'binary':\n",
    "            return self.model.predict_proba(X_test, ntree_limit=self.model.best_iteration)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, ntree_limit=self.model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class MainTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, convert_cyclical: bool = False, create_interactions: bool = False, n_interactions: int = 20):\n",
    "        \"\"\"\n",
    "        Main transformer for the data. Can be used for processing on the whole data.\n",
    "\n",
    "        :param convert_cyclical: convert cyclical features into continuous\n",
    "        :param create_interactions: create interactions between features\n",
    "        \"\"\"\n",
    "\n",
    "        self.convert_cyclical = convert_cyclical\n",
    "        self.create_interactions = create_interactions\n",
    "        self.feats_for_interaction = None\n",
    "        self.n_interactions = n_interactions\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.create_interactions:\n",
    "            self.feats_for_interaction = [col for col in X.columns if 'sum' in col\n",
    "                                          or 'mean' in col or 'max' in col or 'std' in col\n",
    "                                          or 'attempt' in col]\n",
    "            self.feats_for_interaction1 = np.random.choice(self.feats_for_interaction, self.n_interactions)\n",
    "            self.feats_for_interaction2 = np.random.choice(self.feats_for_interaction, self.n_interactions)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "        if self.create_interactions:\n",
    "            for col1 in self.feats_for_interaction1:\n",
    "                for col2 in self.feats_for_interaction2:\n",
    "                    data[f'{col1}_int_{col2}'] = data[col1] * data[col2]\n",
    "\n",
    "        if self.convert_cyclical:\n",
    "            data['timestampHour'] = np.sin(2 * np.pi * data['timestampHour'] / 23.0)\n",
    "            data['timestampMonth'] = np.sin(2 * np.pi * data['timestampMonth'] / 23.0)\n",
    "            data['timestampWeek'] = np.sin(2 * np.pi * data['timestampWeek'] / 23.0)\n",
    "            data['timestampMinute'] = np.sin(2 * np.pi * data['timestampMinute'] / 23.0)\n",
    "\n",
    "#         data['installation_session_count'] = data.groupby(['installation_id'])['Clip'].transform('count')\n",
    "#         data['installation_duration_mean'] = data.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "#         data['installation_title_nunique'] = data.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "\n",
    "#         data['sum_event_code_count'] = data[['2000', '3010', '3110', '4070', '4090', '4030', '4035', '4021', '4020', '4010', '2080', '2083', '2040', '2020', '2030', '3021', '3121', '2050', '3020', '3120', '2060', '2070', '4031', '4025', '5000', '5010', '2081', '2025', '4022', '2035', '4040', '4100', '2010', '4110', '4045', '4095', '4220', '2075', '4230', '4235', '4080', '4050']].sum(axis=1)\n",
    "\n",
    "        # data['installation_event_code_count_mean'] = data.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, main_cat_features: list = None, num_cols: list = None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param main_cat_features:\n",
    "        :param num_cols:\n",
    "        \"\"\"\n",
    "        self.main_cat_features = main_cat_features\n",
    "        self.num_cols = num_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "#         self.num_cols = [col for col in X.columns if 'sum' in col or 'mean' in col or 'max' in col or 'std' in col\n",
    "#                          or 'attempt' in col]\n",
    "        \n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "#         for col in self.num_cols:\n",
    "#             data[f'{col}_to_mean'] = data[col] / data.groupby('installation_id')[col].transform('mean')\n",
    "#             data[f'{col}_to_std'] = data[col] / data.groupby('installation_id')[col].transform('std')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "class RegressorModel(object):\n",
    "    \"\"\"\n",
    "    A wrapper class for classification models.\n",
    "    It can be used for training and prediction.\n",
    "    Can plot feature importance and training progress (if relevant for model).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns: list = None, model_wrapper=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param original_columns:\n",
    "        :param model_wrapper:\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        self.model_wrapper = model_wrapper\n",
    "        self.result_dict = {}\n",
    "        self.train_one_fold = False\n",
    "        self.preprocesser = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y,\n",
    "            X_holdout: pd.DataFrame = None, y_holdout=None,\n",
    "            folds=None,\n",
    "            params: dict = None,\n",
    "            eval_metric='rmse',\n",
    "            cols_to_drop: list = None,\n",
    "            preprocesser=None,\n",
    "            transformers: dict = None,\n",
    "            adversarial: bool = False,\n",
    "            plot: bool = True):\n",
    "        \"\"\"\n",
    "        Training the model.\n",
    "\n",
    "        :param X: training data\n",
    "        :param y: training target\n",
    "        :param X_holdout: holdout data\n",
    "        :param y_holdout: holdout target\n",
    "        :param folds: folds to split the data. If not defined, then model will be trained on the whole X\n",
    "        :param params: training parameters\n",
    "        :param eval_metric: metric for validataion\n",
    "        :param cols_to_drop: list of columns to drop (for example ID)\n",
    "        :param preprocesser: preprocesser class\n",
    "        :param transformers: transformer to use on folds\n",
    "        :param adversarial\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if folds is None:\n",
    "            folds = KFold(n_splits=3, random_state=42)\n",
    "            self.train_one_fold = True\n",
    "\n",
    "        self.columns = X.columns if self.columns is None else self.columns\n",
    "        self.feature_importances = pd.DataFrame(columns=['feature', 'importance'])\n",
    "        self.trained_transformers = {k: [] for k in transformers}\n",
    "        self.transformers = transformers\n",
    "        self.models = []\n",
    "        self.folds_dict = {}\n",
    "        self.eval_metric = eval_metric\n",
    "        n_target = 1\n",
    "        self.oof = np.zeros((len(X), n_target))\n",
    "        self.n_target = n_target\n",
    "\n",
    "        X = X[self.columns]\n",
    "        if X_holdout is not None:\n",
    "            X_holdout = X_holdout[self.columns]\n",
    "\n",
    "        if preprocesser is not None:\n",
    "            self.preprocesser = preprocesser\n",
    "            self.preprocesser.fit(X, y)\n",
    "            X = self.preprocesser.transform(X, y)\n",
    "            self.columns = X.columns.tolist()\n",
    "            if X_holdout is not None:\n",
    "                X_holdout = self.preprocesser.transform(X_holdout)\n",
    "\n",
    "        for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y, X['installation_id'])):\n",
    "\n",
    "            if X_holdout is not None:\n",
    "                X_hold = X_holdout.copy()\n",
    "            else:\n",
    "                X_hold = None\n",
    "            self.folds_dict[fold_n] = {}\n",
    "            if params['verbose']:\n",
    "                print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "            self.folds_dict[fold_n] = {}\n",
    "\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            if self.train_one_fold:\n",
    "                X_train = X[self.original_columns]\n",
    "                y_train = y\n",
    "                X_valid = None\n",
    "                y_valid = None\n",
    "\n",
    "            datasets = {'X_train': X_train, 'X_valid': X_valid, 'X_holdout': X_hold, 'y_train': y_train}\n",
    "            X_train, X_valid, X_hold = self.transform_(datasets, cols_to_drop)\n",
    "\n",
    "            self.folds_dict[fold_n]['columns'] = X_train.columns.tolist()\n",
    "\n",
    "            model = copy.deepcopy(self.model_wrapper)\n",
    "\n",
    "            if adversarial:\n",
    "                X_new1 = X_train.copy()\n",
    "                if X_valid is not None:\n",
    "                    X_new2 = X_valid.copy()\n",
    "                elif X_holdout is not None:\n",
    "                    X_new2 = X_holdout.copy()\n",
    "                X_new = pd.concat([X_new1, X_new2], axis=0)\n",
    "                y_new = np.hstack((np.zeros((X_new1.shape[0])), np.ones((X_new2.shape[0]))))\n",
    "                X_train, X_valid, y_train, y_valid = train_test_split(X_new, y_new)\n",
    "\n",
    "            model.fit(X_train, y_train, X_valid, y_valid, X_hold, y_holdout, params=params)\n",
    "\n",
    "            self.folds_dict[fold_n]['scores'] = model.best_score_\n",
    "            if self.oof.shape[0] != len(X):\n",
    "                self.oof = np.zeros((X.shape[0], self.oof.shape[1]))\n",
    "            if not adversarial:\n",
    "                self.oof[valid_index] = model.predict(X_valid).reshape(-1, n_target)\n",
    "\n",
    "            fold_importance = pd.DataFrame(list(zip(X_train.columns, model.feature_importances_)),\n",
    "                                           columns=['feature', 'importance'])\n",
    "            self.feature_importances = self.feature_importances.append(fold_importance)\n",
    "            self.models.append(model)\n",
    "\n",
    "        self.feature_importances['importance'] = self.feature_importances['importance'].astype(int)\n",
    "\n",
    "        # if params['verbose']:\n",
    "        self.calc_scores_()\n",
    "\n",
    "        if plot:\n",
    "            # print(classification_report(y, self.oof.argmax(1)))\n",
    "            fig, ax = plt.subplots(figsize=(16, 12))\n",
    "            plt.subplot(2, 2, 1)\n",
    "            self.plot_feature_importance(top_n=20)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            self.plot_metric()\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.hist(y.values.reshape(-1, 1) - self.oof)\n",
    "            plt.title('Distribution of errors')\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.hist(self.oof)\n",
    "            plt.title('Distribution of oof predictions');\n",
    "\n",
    "    def transform_(self, datasets, cols_to_drop):\n",
    "        for name, transformer in self.transformers.items():\n",
    "            transformer.fit(datasets['X_train'], datasets['y_train'])\n",
    "            datasets['X_train'] = transformer.transform(datasets['X_train'])\n",
    "            if datasets['X_valid'] is not None:\n",
    "                datasets['X_valid'] = transformer.transform(datasets['X_valid'])\n",
    "            if datasets['X_holdout'] is not None:\n",
    "                datasets['X_holdout'] = transformer.transform(datasets['X_holdout'])\n",
    "            self.trained_transformers[name].append(transformer)\n",
    "        if cols_to_drop is not None:\n",
    "            cols_to_drop = [col for col in cols_to_drop if col in datasets['X_train'].columns]\n",
    "\n",
    "            datasets['X_train'] = datasets['X_train'].drop(cols_to_drop, axis=1)\n",
    "            if datasets['X_valid'] is not None:\n",
    "                datasets['X_valid'] = datasets['X_valid'].drop(cols_to_drop, axis=1)\n",
    "            if datasets['X_holdout'] is not None:\n",
    "                datasets['X_holdout'] = datasets['X_holdout'].drop(cols_to_drop, axis=1)\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "\n",
    "        return datasets['X_train'], datasets['X_valid'], datasets['X_holdout']\n",
    "\n",
    "    def calc_scores_(self):\n",
    "        print()\n",
    "        datasets = [k for k, v in [v['scores'] for k, v in self.folds_dict.items()][0].items() if len(v) > 0]\n",
    "        self.scores = {}\n",
    "        for d in datasets:\n",
    "            scores = [v['scores'][d][self.eval_metric] for k, v in self.folds_dict.items()]\n",
    "            print(f\"CV mean score on {d}: {np.mean(scores):.4f} +/- {np.std(scores):.4f} std.\")\n",
    "            self.scores[d] = np.mean(scores)\n",
    "\n",
    "    def predict(self, X_test, averaging: str = 'usual'):\n",
    "        \"\"\"\n",
    "        Make prediction\n",
    "\n",
    "        :param X_test:\n",
    "        :param averaging: method of averaging\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_prediction = np.zeros((X_test.shape[0], self.oof.shape[1]))\n",
    "        if self.preprocesser is not None:\n",
    "            X_test = self.preprocesser.transform(X_test)\n",
    "        for i in range(len(self.models)):\n",
    "            X_t = X_test.copy()\n",
    "            for name, transformers in self.trained_transformers.items():\n",
    "                X_t = transformers[i].transform(X_t)\n",
    "\n",
    "            if self.cols_to_drop is not None:\n",
    "                cols_to_drop = [col for col in self.cols_to_drop if col in X_t.columns]\n",
    "                X_t = X_t.drop(cols_to_drop, axis=1)\n",
    "            y_pred = self.models[i].predict(X_t[self.folds_dict[i]['columns']]).reshape(-1, full_prediction.shape[1])\n",
    "\n",
    "            # if case transformation changes the number of the rows\n",
    "            if full_prediction.shape[0] != len(y_pred):\n",
    "                full_prediction = np.zeros((y_pred.shape[0], self.oof.shape[1]))\n",
    "\n",
    "            if averaging == 'usual':\n",
    "                full_prediction += y_pred\n",
    "            elif averaging == 'rank':\n",
    "                full_prediction += pd.Series(y_pred).rank().values\n",
    "\n",
    "        return full_prediction / len(self.models)\n",
    "\n",
    "    def plot_feature_importance(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Plot default feature importance.\n",
    "\n",
    "        :param drop_null_importance: drop columns with null feature importance\n",
    "        :param top_n: show top n columns\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        top_feats = self.get_top_features(drop_null_importance, top_n)\n",
    "        feature_importances = self.feature_importances.loc[self.feature_importances['feature'].isin(top_feats)]\n",
    "        feature_importances['feature'] = feature_importances['feature'].astype(str)\n",
    "        top_feats = [str(i) for i in top_feats]\n",
    "        sns.barplot(data=feature_importances, x='importance', y='feature', orient='h', order=top_feats)\n",
    "        plt.title('Feature importances')\n",
    "\n",
    "    def get_top_features(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Get top features by importance.\n",
    "\n",
    "        :param drop_null_importance:\n",
    "        :param top_n:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grouped_feats = self.feature_importances.groupby(['feature'])['importance'].mean()\n",
    "        if drop_null_importance:\n",
    "            grouped_feats = grouped_feats[grouped_feats != 0]\n",
    "        return list(grouped_feats.sort_values(ascending=False).index)[:top_n]\n",
    "\n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "        Plot training progress.\n",
    "        Inspired by `plot_metric` from https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/plotting.html\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_evals_results = pd.DataFrame()\n",
    "        for model in self.models:\n",
    "            evals_result = pd.DataFrame()\n",
    "            for k in model.model.evals_result_.keys():\n",
    "                evals_result[k] = model.model.evals_result_[k][self.eval_metric]\n",
    "            evals_result = evals_result.reset_index().rename(columns={'index': 'iteration'})\n",
    "            full_evals_results = full_evals_results.append(evals_result)\n",
    "\n",
    "        full_evals_results = full_evals_results.melt(id_vars=['iteration']).rename(columns={'value': self.eval_metric,\n",
    "                                                                                            'variable': 'dataset'})\n",
    "        sns.lineplot(data=full_evals_results, x='iteration', y=self.eval_metric, hue='dataset')\n",
    "        plt.title('Training progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''additional features in function'''\n",
    "\n",
    "list_of_prac = list(set(train['practice_sec'].unique()).union(set(test['practice_sec'].unique())))\n",
    "list_of_phase = list(set(train['time_by_phase_type'].unique()).union(set(test['time_by_phase_type'].unique())))\n",
    "list_of_recent_ratio = list(set(train['recent_ratio'].unique()).union(set(test['recent_ratio'].unique())))\n",
    "list_of_total = list(set(train['total_game_time'].unique()).union(set(test['total_game_time'].unique())))\n",
    "list_of_months = list(set(train['months_played'].unique()).union(set(test['months_played'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0,\n",
       " 32768.14: 0,\n",
       " 32769.582: 0,\n",
       " 65539.22: 0,\n",
       " 3.25: 0,\n",
       " 32777.785: 0,\n",
       " 14.5: 0,\n",
       " 65553.48: 0,\n",
       " 19.0: 0,\n",
       " 32788.055: 0,\n",
       " 32792.42: 0,\n",
       " 32799.273: 0,\n",
       " 32.266666: 0,\n",
       " 32801.332: 0,\n",
       " 32806.277: 0,\n",
       " 40.533333: 0,\n",
       " 32809.086: 0,\n",
       " 32810.516: 0,\n",
       " 32811.883: 0,\n",
       " 32812.273: 0,\n",
       " 32821.832: 0,\n",
       " 32828.53: 0,\n",
       " 61.5: 0,\n",
       " 131138.97: 0,\n",
       " 71.4: 0,\n",
       " 71.1: 0,\n",
       " 32845.203: 0,\n",
       " 65614.586: 0,\n",
       " 65615.15: 0,\n",
       " 32850.582: 0,\n",
       " 32856.676: 0,\n",
       " 92.03333: 0,\n",
       " 32861.297: 0,\n",
       " 95.76667: 0,\n",
       " 103.76667: 0,\n",
       " 65644.7: 0,\n",
       " 108.87143: 0,\n",
       " 32889.223: 0,\n",
       " 124.46667: 0,\n",
       " 130.6125: 0,\n",
       " 135.75: 0,\n",
       " 65676.695: 0,\n",
       " 32913.863: 0,\n",
       " 32914.484: 0,\n",
       " 151.95: 0,\n",
       " 65690.45: 0,\n",
       " 32925.227: 0,\n",
       " 32934.437999999995: 0,\n",
       " 32934.926: 0,\n",
       " 32936.11: 0,\n",
       " 32939.574: 0,\n",
       " 176.57143: 0,\n",
       " 178.625: 0,\n",
       " 181.02: 0,\n",
       " 182.08: 0,\n",
       " 184.575: 0,\n",
       " 186.8: 0,\n",
       " 187.825: 0,\n",
       " 189.675: 0,\n",
       " 32959.184: 0,\n",
       " 32959.957: 0,\n",
       " 32961.36: 0,\n",
       " 65729.75: 0,\n",
       " 32962.484: 0,\n",
       " 194.775: 0,\n",
       " 32959.35: 0,\n",
       " 32966.684: 0,\n",
       " 206.6625: 0,\n",
       " 209.625: 0,\n",
       " 32979.77: 0,\n",
       " 211.65: 0,\n",
       " 213.25: 0,\n",
       " 214.6625: 0,\n",
       " 214.575: 0,\n",
       " 216.7: 0,\n",
       " 32982.54: 0,\n",
       " 32987.293: 0,\n",
       " 220.55295: 0,\n",
       " 32990.67: 0,\n",
       " 32991.17: 0,\n",
       " 32995.734: 0,\n",
       " 228.44: 0,\n",
       " 228.03334: 0,\n",
       " 33012.66: 0,\n",
       " 33013.723: 0,\n",
       " 246.2: 0,\n",
       " 257.22: 0,\n",
       " 259.64062: 0,\n",
       " 33027.937999999995: 0,\n",
       " 33029.39: 0,\n",
       " 263.8: 0,\n",
       " 266.22: 0,\n",
       " 98571.87: 0,\n",
       " 268.03333: 0,\n",
       " 268.98: 0,\n",
       " 33036.28: 0,\n",
       " 271.3: 0,\n",
       " 271.01764: 0,\n",
       " 33047.6: 0,\n",
       " 280.66: 0,\n",
       " 33047.34: 0,\n",
       " 282.0375: 0,\n",
       " 282.66: 0,\n",
       " 196891.6: 0,\n",
       " 33052.79: 0,\n",
       " 33055.234: 0,\n",
       " 287.42: 0,\n",
       " 288.84: 0,\n",
       " 33057.96: 0,\n",
       " 291.35626: 0,\n",
       " 33056.06: 0,\n",
       " 295.78583: 0,\n",
       " 298.56: 0,\n",
       " 33069.17: 0,\n",
       " 301.48334: 0,\n",
       " 306.01666: 0,\n",
       " 311.7: 0,\n",
       " 33079.137: 0,\n",
       " 311.95: 0,\n",
       " 33083.945: 0,\n",
       " 316.88: 0,\n",
       " 323.8: 0,\n",
       " 33091.598: 0,\n",
       " 323.6: 0,\n",
       " 327.1: 0,\n",
       " 331.0111: 0,\n",
       " 33103.957: 0,\n",
       " 336.8: 0,\n",
       " 33105.68: 0,\n",
       " 338.48: 0,\n",
       " 340.35: 0,\n",
       " 342.575: 0,\n",
       " 131415.75: 0,\n",
       " 344.6625: 0,\n",
       " 345.8133200000001: 0,\n",
       " 344.27856: 0,\n",
       " 344.175: 0,\n",
       " 348.0: 0,\n",
       " 33116.473: 0,\n",
       " 351.96: 0,\n",
       " 353.65: 0,\n",
       " 357.65: 0,\n",
       " 358.13333: 0,\n",
       " 358.65: 0,\n",
       " 359.8: 0,\n",
       " 358.76666: 0,\n",
       " 33130.55: 0,\n",
       " 358.8: 0,\n",
       " 363.35: 0,\n",
       " 373.26923: 0,\n",
       " 376.9: 0,\n",
       " 377.96786: 0,\n",
       " 385.65625: 0,\n",
       " 386.4: 0,\n",
       " 385.9125: 0,\n",
       " 388.5: 0,\n",
       " 164228.03: 0,\n",
       " 390.36: 0,\n",
       " 390.06: 0,\n",
       " 389.92: 0,\n",
       " 65927.555: 0,\n",
       " 33162.258: 0,\n",
       " 395.62: 0,\n",
       " 33164.41: 0,\n",
       " 395.35: 0,\n",
       " 33166.777: 0,\n",
       " 33170.566: 0,\n",
       " 404.8: 0,\n",
       " 405.7: 0,\n",
       " 406.5: 0,\n",
       " 405.73334: 0,\n",
       " 33174.355: 0,\n",
       " 408.82272: 0,\n",
       " 412.1625: 0,\n",
       " 33180.703: 0,\n",
       " 414.43076: 0,\n",
       " 65951.35: 0,\n",
       " 415.8: 0,\n",
       " 415.05: 0,\n",
       " 33185.92: 0,\n",
       " 419.02222: 0,\n",
       " 423.3: 0,\n",
       " 424.49167: 0,\n",
       " 33196.926: 0,\n",
       " 429.16428: 0,\n",
       " 65965.62: 0,\n",
       " 431.61667: 0,\n",
       " 433.2: 0,\n",
       " 435.2143: 0,\n",
       " 33204.145: 0,\n",
       " 33205.113: 0,\n",
       " 33206.977: 0,\n",
       " 439.875: 0,\n",
       " 65984.4: 0,\n",
       " 449.13: 0,\n",
       " 451.35: 0,\n",
       " 452.0643: 0,\n",
       " 455.8298: 0,\n",
       " 33224.062000000005: 0,\n",
       " 458.25: 0,\n",
       " 459.06: 0,\n",
       " 33228.145: 0,\n",
       " 33226.55: 0,\n",
       " 465.975: 0,\n",
       " 469.88: 0,\n",
       " 470.575: 0,\n",
       " 471.02078: 0,\n",
       " 469.6125: 0,\n",
       " 66009.29: 0,\n",
       " 33242.086: 0,\n",
       " 475.55: 0,\n",
       " 478.4: 0,\n",
       " 33247.36: 0,\n",
       " 480.53: 0,\n",
       " 33247.844: 0,\n",
       " 479.91666: 0,\n",
       " 478.3: 0,\n",
       " 481.5: 0,\n",
       " 485.14: 0,\n",
       " 486.42: 0,\n",
       " 33253.492: 0,\n",
       " 486.96: 0,\n",
       " 486.85: 0,\n",
       " 490.1: 0,\n",
       " 33260.41: 0,\n",
       " 33263.54: 0,\n",
       " 33273.48: 0,\n",
       " 33275.27: 0,\n",
       " 33277.99: 0,\n",
       " 510.88: 0,\n",
       " 510.3: 0,\n",
       " 33279.73: 0,\n",
       " 509.77435: 0,\n",
       " 33282.16: 0,\n",
       " 33283.24: 0,\n",
       " 516.44666: 0,\n",
       " 517.7: 0,\n",
       " 518.9423: 0,\n",
       " 66055.734: 0,\n",
       " 33289.832: 0,\n",
       " 522.4267: 0,\n",
       " 522.65454: 0,\n",
       " 521.85: 0,\n",
       " 33293.555: 0,\n",
       " 528.72: 0,\n",
       " 529.0875: 0,\n",
       " 33298.145: 0,\n",
       " 33297.31: 0,\n",
       " 532.84: 0,\n",
       " 33301.03: 0,\n",
       " 529.2778: 0,\n",
       " 538.14: 0,\n",
       " 33307.81: 0,\n",
       " 66076.76: 0,\n",
       " 328220.6: 0,\n",
       " 542.58: 0,\n",
       " 33311.77: 0,\n",
       " 544.54443: 0,\n",
       " 33312.53: 0,\n",
       " 33314.332: 0,\n",
       " 548.425: 0,\n",
       " 164393.45: 0,\n",
       " 555.51117: 0,\n",
       " 33325.35: 0,\n",
       " 558.9: 0,\n",
       " 558.85: 0,\n",
       " 558.4828: 0,\n",
       " 33329.297: 0,\n",
       " 561.78: 0,\n",
       " 559.5375: 0,\n",
       " 33328.723: 0,\n",
       " 565.79: 0,\n",
       " 565.43335: 0,\n",
       " 33335.566: 0,\n",
       " 569.64734: 0,\n",
       " 33337.43: 0,\n",
       " 571.08: 0,\n",
       " 571.34: 0,\n",
       " 33340.324: 0,\n",
       " 575.875: 0,\n",
       " 578.9167: 0,\n",
       " 579.3: 0,\n",
       " 33349.02: 0,\n",
       " 582.65: 0,\n",
       " 582.65454: 0,\n",
       " 584.82: 0,\n",
       " 584.1: 0,\n",
       " 33355.91: 0,\n",
       " 590.91113: 0,\n",
       " 591.89636: 0,\n",
       " 33361.86: 0,\n",
       " 596.9308: 0,\n",
       " 596.775: 0,\n",
       " 596.9867: 0,\n",
       " 601.17334: 0,\n",
       " 603.8333: 0,\n",
       " 33373.523: 0,\n",
       " 607.50665: 0,\n",
       " 66144.375: 0,\n",
       " 611.41: 0,\n",
       " 33379.527: 0,\n",
       " 612.024: 0,\n",
       " 617.22: 0,\n",
       " 619.22: 0,\n",
       " 619.02: 0,\n",
       " 33390.293: 0,\n",
       " 623.0: 0,\n",
       " 33391.383: 0,\n",
       " 623.025: 0,\n",
       " 626.6: 0,\n",
       " 626.4: 0,\n",
       " 628.01666: 0,\n",
       " 33397.457: 0,\n",
       " 625.91: 0,\n",
       " 631.86: 0,\n",
       " 33400.93: 0,\n",
       " 66170.92: 0,\n",
       " 636.5880000000002: 0,\n",
       " 637.9071700000002: 0,\n",
       " 636.78: 0,\n",
       " 640.0571: 0,\n",
       " 642.2526: 0,\n",
       " 649.52: 0,\n",
       " 649.29: 0,\n",
       " 33418.152: 0,\n",
       " 33421.723: 0,\n",
       " 33423.344: 0,\n",
       " 655.64: 0,\n",
       " 657.26: 0,\n",
       " 659.79: 0,\n",
       " 661.18: 0,\n",
       " 663.56: 0,\n",
       " 33432.996: 0,\n",
       " 667.7833: 0,\n",
       " 668.3: 0,\n",
       " 33439.836: 0,\n",
       " 673.1625: 0,\n",
       " 677.4562400000002: 0,\n",
       " 33449.844: 0,\n",
       " 682.34: 0,\n",
       " 683.87: 0,\n",
       " 683.85: 0,\n",
       " 686.04: 0,\n",
       " 33455.35: 0,\n",
       " 687.95: 0,\n",
       " 33457.812000000005: 0,\n",
       " 690.8625: 0,\n",
       " 693.6: 0,\n",
       " 393915.66: 0,\n",
       " 700.5: 0,\n",
       " 699.24: 0,\n",
       " 700.02: 0,\n",
       " 33471.246: 0,\n",
       " 701.7476: 0,\n",
       " 33473.613: 0,\n",
       " 704.99335: 0,\n",
       " 707.325: 0,\n",
       " 700.5333: 0,\n",
       " 33478.676: 0,\n",
       " 712.80835: 0,\n",
       " 33482.547: 0,\n",
       " 33484.89: 0,\n",
       " 33487.44: 0,\n",
       " 33488.87: 0,\n",
       " 721.4225: 0,\n",
       " 719.94: 0,\n",
       " 33492.0: 0,\n",
       " 33493.24: 0,\n",
       " 33495.965: 0,\n",
       " 33496.04: 0,\n",
       " 131800.22: 0,\n",
       " 730.4767: 0,\n",
       " 33497.645: 0,\n",
       " 732.8143: 0,\n",
       " 735.59546: 0,\n",
       " 737.36: 0,\n",
       " 738.25: 0,\n",
       " 744.7875: 0,\n",
       " 33518.7: 0,\n",
       " 33520.15: 0,\n",
       " 754.7: 0,\n",
       " 33525.277: 0,\n",
       " 757.08826: 0,\n",
       " 759.1373: 0,\n",
       " 759.2839: 0,\n",
       " 761.19: 0,\n",
       " 758.18665: 0,\n",
       " 33533.887: 0,\n",
       " 164609.06: 0,\n",
       " 772.18: 0,\n",
       " 775.1813: 0,\n",
       " 33544.324: 0,\n",
       " 778.14667: 0,\n",
       " 781.905: 0,\n",
       " 782.828: 0,\n",
       " 783.4: 0,\n",
       " 783.81: 0,\n",
       " 786.1: 0,\n",
       " 787.3989: 0,\n",
       " 786.4125: 0,\n",
       " 789.81: 0,\n",
       " 790.1: 0,\n",
       " 33557.6: 0,\n",
       " 791.88: 0,\n",
       " 793.078: 0,\n",
       " 787227.7: 0,\n",
       " 796.0389: 0,\n",
       " 33565.668: 0,\n",
       " 799.76666: 0,\n",
       " 799.89233: 0,\n",
       " 801.815: 0,\n",
       " 803.38666: 0,\n",
       " 805.54: 0,\n",
       " 806.375: 0,\n",
       " 808.8560000000001: 0,\n",
       " 33576.496: 0,\n",
       " 814.86: 0,\n",
       " 816.3428299999998: 0,\n",
       " 33584.64: 0,\n",
       " 819.67426: 0,\n",
       " 819.92: 0,\n",
       " 821.4083: 0,\n",
       " 827.13: 0,\n",
       " 827.73: 0,\n",
       " 66366.65: 0,\n",
       " 834.2714: 0,\n",
       " 841.50665: 0,\n",
       " 843.375: 0,\n",
       " 33615.3: 0,\n",
       " 848.1407: 0,\n",
       " 33617.42: 0,\n",
       " 849.2: 0,\n",
       " 33620.375: 0,\n",
       " 853.8298300000001: 0,\n",
       " 33621.69: 0,\n",
       " 131926.75: 0,\n",
       " 33626.72: 0,\n",
       " 426842.9: 0,\n",
       " 859.14: 0,\n",
       " 863.5154: 0,\n",
       " 66403.73: 0,\n",
       " 868.69714: 0,\n",
       " 33636.187999999995: 0,\n",
       " 33639.652: 0,\n",
       " 874.4: 0,\n",
       " 875.67035: 0,\n",
       " 33644.34: 0,\n",
       " 877.6039999999998: 0,\n",
       " 880.5736699999999: 0,\n",
       " 882.4: 0,\n",
       " 883.0933: 0,\n",
       " 883.5133: 0,\n",
       " 888.1: 0,\n",
       " 889.675: 0,\n",
       " 893.325: 0,\n",
       " 33662.812000000005: 0,\n",
       " 33663.633: 0,\n",
       " 900.335: 0,\n",
       " 66437.94: 0,\n",
       " 903.94617: 0,\n",
       " 904.7769: 0,\n",
       " 918.96: 0,\n",
       " 328600.0: 0,\n",
       " 921.82666: 0,\n",
       " 33690.19: 0,\n",
       " 922.68: 0,\n",
       " 920.34: 0,\n",
       " 33694.918: 0,\n",
       " 66465.21: 0,\n",
       " 930.36: 0,\n",
       " 931.40454: 0,\n",
       " 33699.65: 0,\n",
       " 33701.184: 0,\n",
       " 33705.594: 0,\n",
       " 938.8: 0,\n",
       " 33707.105: 0,\n",
       " 940.775: 0,\n",
       " 941.1675: 0,\n",
       " 937.87933: 0,\n",
       " 33711.86: 0,\n",
       " 33712.31: 0,\n",
       " 948.2241: 0,\n",
       " 948.93787: 0,\n",
       " 33720.586: 0,\n",
       " 957.2711: 0,\n",
       " 960.03: 0,\n",
       " 33731.754: 0,\n",
       " 33731.945: 0,\n",
       " 966.84: 0,\n",
       " 969.11816: 0,\n",
       " 970.88336: 0,\n",
       " 971.34: 0,\n",
       " 973.17: 0,\n",
       " 977.92145: 0,\n",
       " 978.7091: 0,\n",
       " 33747.12: 0,\n",
       " 99281.97: 0,\n",
       " 33749.074: 0,\n",
       " 983.28: 0,\n",
       " 33752.77: 0,\n",
       " 985.2267: 0,\n",
       " 33754.31: 0,\n",
       " 33756.07: 0,\n",
       " 989.4429: 0,\n",
       " 990.81: 0,\n",
       " 990.405: 0,\n",
       " 991.86: 0,\n",
       " 996.6445: 0,\n",
       " 998.0722: 0,\n",
       " 999.91113: 0,\n",
       " 999.175: 0,\n",
       " 999.6: 0,\n",
       " 1004.0933: 0,\n",
       " 1005.69: 0,\n",
       " 33777.74: 0,\n",
       " 1013.025: 0,\n",
       " 33785.633: 0,\n",
       " 33786.113: 0,\n",
       " 1019.69165: 0,\n",
       " 1021.80835: 0,\n",
       " 1022.67: 0,\n",
       " 33791.074: 0,\n",
       " 1022.58: 0,\n",
       " 1021.3333: 0,\n",
       " 1027.2806: 0,\n",
       " 33796.293: 0,\n",
       " 33801.38: 0,\n",
       " 33802.336: 0,\n",
       " 66571.73: 0,\n",
       " 1039.2072: 0,\n",
       " 1042.66: 0,\n",
       " 1043.31: 0,\n",
       " 33812.71: 0,\n",
       " 1045.1417: 0,\n",
       " 1047.025: 0,\n",
       " 1048.3077: 0,\n",
       " 1051.8971: 0,\n",
       " 1052.6125: 0,\n",
       " 1052.3625: 0,\n",
       " 1057.83: 0,\n",
       " 1063.875: 0,\n",
       " 33832.504: 0,\n",
       " 1065.963: 0,\n",
       " 1066.0731: 0,\n",
       " 1067.76: 0,\n",
       " 33837.04: 0,\n",
       " 1070.8773: 0,\n",
       " 1072.4: 0,\n",
       " 1072.48: 0,\n",
       " 1072.1625: 0,\n",
       " 1077.645: 0,\n",
       " 1081.7866: 0,\n",
       " 1081.625: 0,\n",
       " 1083.2046: 0,\n",
       " 1088.675: 0,\n",
       " 33856.797: 0,\n",
       " 33858.246: 0,\n",
       " 33861.797: 0,\n",
       " 1095.3136: 0,\n",
       " 66633.55: 0,\n",
       " 1098.6575: 0,\n",
       " 1099.88: 0,\n",
       " 1100.05: 0,\n",
       " 33871.055: 0,\n",
       " 1106.4242: 0,\n",
       " 1106.935: 0,\n",
       " 1111.6285: 0,\n",
       " 1112.6692: 0,\n",
       " 99421.81: 0,\n",
       " 33885.77: 0,\n",
       " 1119.625: 0,\n",
       " 1120.98: 0,\n",
       " 1120.797: 0,\n",
       " 1121.4417: 0,\n",
       " 1122.33: 0,\n",
       " 1125.7866: 0,\n",
       " 1127.9441: 0,\n",
       " 1127.61: 0,\n",
       " 1129.65: 0,\n",
       " 99436.23: 0,\n",
       " 1134.2234: 0,\n",
       " 1135.7545: 0,\n",
       " 1135.6: 0,\n",
       " 1137.9626: 0,\n",
       " 1145.279: 0,\n",
       " 33915.613: 0,\n",
       " 1148.724: 0,\n",
       " 1149.57: 0,\n",
       " 33917.207: 0,\n",
       " 33920.54: 0,\n",
       " 1154.5: 0,\n",
       " 99458.914: 0,\n",
       " 1156.89: 0,\n",
       " 1159.5: 0,\n",
       " 1160.5667: 0,\n",
       " 33930.203: 0,\n",
       " 1162.7367: 0,\n",
       " 1164.34: 0,\n",
       " 1164.425: 0,\n",
       " 1165.2808: 0,\n",
       " 33935.023: 0,\n",
       " 1171.53: 0,\n",
       " 1172.6625: 0,\n",
       " 1174.9714: 0,\n",
       " 1175.5125: 0,\n",
       " 1176.5358: 0,\n",
       " 1176.9893: 0,\n",
       " 66722.46: 0,\n",
       " 33956.19: 0,\n",
       " 1191.045: 0,\n",
       " 1192.1: 0,\n",
       " 33961.766: 0,\n",
       " 1193.6581: 0,\n",
       " 1196.36: 0,\n",
       " 33965.797: 0,\n",
       " 33968.82: 0,\n",
       " 1200.84: 0,\n",
       " 1205.271: 0,\n",
       " 1206.5605: 0,\n",
       " 33980.645: 0,\n",
       " 1213.0072: 0,\n",
       " 1213.49: 0,\n",
       " 1218.15: 0,\n",
       " 1219.0: 0,\n",
       " 1220.16: 0,\n",
       " 1218.7795: 0,\n",
       " 33990.367: 0,\n",
       " 1223.9539: 0,\n",
       " 1226.0062: 0,\n",
       " 1229.296: 0,\n",
       " 1230.029: 0,\n",
       " 1230.3: 0,\n",
       " 1234.4948: 0,\n",
       " 34003.562000000005: 0,\n",
       " 1235.5878: 0,\n",
       " 1238.1318: 0,\n",
       " 34007.98: 0,\n",
       " 1239.9143: 0,\n",
       " 34009.742: 0,\n",
       " 34010.15: 0,\n",
       " 1241.31: 0,\n",
       " 34012.4: 0,\n",
       " 1245.5764: 0,\n",
       " 1246.5: 0,\n",
       " 1244.0813: 0,\n",
       " 1248.3514: 0,\n",
       " 34019.97: 0,\n",
       " 1252.0442: 0,\n",
       " 1251.5946: 0,\n",
       " 34025.227: 0,\n",
       " 1257.308: 0,\n",
       " 1257.8862: 0,\n",
       " 34028.637: 0,\n",
       " 263405.53: 0,\n",
       " 1264.1428: 0,\n",
       " 1264.5675: 0,\n",
       " 1272.5938: 0,\n",
       " 66809.32: 0,\n",
       " 1274.98: 0,\n",
       " 34043.324: 0,\n",
       " 1274.7733: 0,\n",
       " 1275.175: 0,\n",
       " 1278.7: 0,\n",
       " 34040.684: 0,\n",
       " 1281.25: 0,\n",
       " 1284.07: 0,\n",
       " 1285.0231: 0,\n",
       " 1286.8683: 0,\n",
       " 1284.085: 0,\n",
       " 1288.4812: 0,\n",
       " 1289.9191: 0,\n",
       " 1292.5464: 0,\n",
       " 66830.016: 0,\n",
       " 34063.41: 0,\n",
       " 1297.2195: 0,\n",
       " 34068.65: 0,\n",
       " 1302.2468: 0,\n",
       " 1303.6719: 0,\n",
       " 66844.6: 0,\n",
       " 1309.7: 0,\n",
       " 66846.91: 0,\n",
       " 34083.18: 0,\n",
       " 1318.5: 0,\n",
       " 1318.8857: 0,\n",
       " 1324.5375: 0,\n",
       " 1327.06: 0,\n",
       " 1328.1459: 0,\n",
       " 1327.4667: 0,\n",
       " 1330.145: 0,\n",
       " 1331.6486: 0,\n",
       " 1332.1033: 0,\n",
       " 1333.8542: 0,\n",
       " 1334.4684: 0,\n",
       " 34102.336: 0,\n",
       " 1334.5: 0,\n",
       " 1330.175: 0,\n",
       " 1339.275: 0,\n",
       " 34108.742: 0,\n",
       " 34109.293: 0,\n",
       " 1343.255: 0,\n",
       " 1343.368: 0,\n",
       " 34114.156: 0,\n",
       " 34115.184: 0,\n",
       " 1349.6442: 0,\n",
       " 34118.46: 0,\n",
       " 1351.9631: 0,\n",
       " 1351.7833: 0,\n",
       " 66889.85: 0,\n",
       " 34121.02: 0,\n",
       " 1355.4231: 0,\n",
       " 1353.94: 0,\n",
       " 1354.75: 0,\n",
       " 1358.975: 0,\n",
       " 1359.5538: 0,\n",
       " 1359.0231: 0,\n",
       " 1359.6333: 0,\n",
       " 1361.9833: 0,\n",
       " 99667.19: 0,\n",
       " 34132.848: 0,\n",
       " 34133.496: 0,\n",
       " 1366.12: 0,\n",
       " 1367.3833: 0,\n",
       " 1368.9429: 0,\n",
       " 1368.7858: 0,\n",
       " 34145.53: 0,\n",
       " 1378.3688: 0,\n",
       " 1378.17: 0,\n",
       " 1378.7854: 0,\n",
       " 1381.9636: 0,\n",
       " 1381.61: 0,\n",
       " 1383.0765: 0,\n",
       " 1382.7567: 0,\n",
       " 34150.098: 0,\n",
       " 34154.88: 0,\n",
       " 1387.375: 0,\n",
       " 1385.625: 0,\n",
       " 1390.14: 0,\n",
       " 1393.335: 0,\n",
       " 1394.6: 0,\n",
       " 1400.2979999999998: 0,\n",
       " 1401.8933: 0,\n",
       " 1402.3715: 0,\n",
       " 1404.0902: 0,\n",
       " 66940.07: 0,\n",
       " 1406.8875: 0,\n",
       " 1404.6637: 0,\n",
       " 1410.5457: 0,\n",
       " 34181.215: 0,\n",
       " 1414.3228: 0,\n",
       " 1415.8887: 0,\n",
       " 1415.845: 0,\n",
       " 1414.6844: 0,\n",
       " 1414.0942: 0,\n",
       " 1419.4546: 0,\n",
       " 1420.4956: 0,\n",
       " 1423.6318: 0,\n",
       " 1423.9281: 0,\n",
       " 1426.38: 0,\n",
       " 1426.7195: 0,\n",
       " 1434.9653: 0,\n",
       " 1434.75: 0,\n",
       " 1434.1533: 0,\n",
       " 34207.16: 0,\n",
       " 34210.27: 0,\n",
       " 1442.1: 0,\n",
       " 34214.24: 0,\n",
       " 1447.9283: 0,\n",
       " 1449.5895: 0,\n",
       " 1453.95: 0,\n",
       " 1453.4392: 0,\n",
       " 1455.03: 0,\n",
       " 34221.25: 0,\n",
       " 1458.0: 0,\n",
       " 1460.8729999999996: 0,\n",
       " 1467.1482: 0,\n",
       " 34237.37: 0,\n",
       " 34238.46: 0,\n",
       " 34239.918: 0,\n",
       " 34240.63: 0,\n",
       " 1473.3667: 0,\n",
       " 1474.7167: 0,\n",
       " 1475.8743: 0,\n",
       " 1478.3667: 0,\n",
       " 1483.725: 0,\n",
       " 1483.8656: 0,\n",
       " 1486.425: 0,\n",
       " 1490.364: 0,\n",
       " 1491.8469: 0,\n",
       " 67027.484: 0,\n",
       " 1494.755: 0,\n",
       " 1497.9875: 0,\n",
       " 1498.2217: 0,\n",
       " 1501.5845: 0,\n",
       " 34269.82: 0,\n",
       " 34271.8: 0,\n",
       " 1504.058: 0,\n",
       " 1510.2762: 0,\n",
       " 1514.875: 0,\n",
       " 1515.9648: 0,\n",
       " 1516.57: 0,\n",
       " 1515.88: 0,\n",
       " 34287.996: 0,\n",
       " 1525.8585: 0,\n",
       " 1526.8: 0,\n",
       " 1525.0171: 0,\n",
       " 1525.4968: 0,\n",
       " 1529.1345: 0,\n",
       " 1531.3944: 0,\n",
       " 1531.208: 0,\n",
       " 1534.9586: 0,\n",
       " 1539.4943: 0,\n",
       " 34311.695: 0,\n",
       " 1544.9543: 0,\n",
       " 1543.8182: 0,\n",
       " 1545.096: 0,\n",
       " 34315.88: 0,\n",
       " 1549.5969: 0,\n",
       " 1550.04: 0,\n",
       " 1549.1045: 0,\n",
       " 1552.8773: 0,\n",
       " 1553.5818: 0,\n",
       " 1554.9137: 0,\n",
       " 34321.676: 0,\n",
       " 1555.1025: 0,\n",
       " 34317.14: 0,\n",
       " 34326.902: 0,\n",
       " 1550.197: 0,\n",
       " 1556.9943: 0,\n",
       " 34330.836: 0,\n",
       " 1568.7426: 0,\n",
       " 1573.7533: 0,\n",
       " 1574.2625: 0,\n",
       " 1575.984: 0,\n",
       " 99879.914: 0,\n",
       " 34345.88: 0,\n",
       " 1575.9375: 0,\n",
       " 1581.7607: 0,\n",
       " 1582.4124: 0,\n",
       " 1585.38: 0,\n",
       " 1586.4187: 0,\n",
       " 34353.12: 0,\n",
       " 1588.545: 0,\n",
       " 1590.8684: 0,\n",
       " 1590.4452: 0,\n",
       " 1590.0272: 0,\n",
       " 34362.008: 0,\n",
       " 1596.4393: 0,\n",
       " 34367.687999999995: 0,\n",
       " 1603.0258: 0,\n",
       " 1604.0173: 0,\n",
       " 34371.918: 0,\n",
       " 99907.875: 0,\n",
       " 1608.3293: 0,\n",
       " 1609.42: 0,\n",
       " 1612.4342: 0,\n",
       " 34380.207: 0,\n",
       " 34384.805: 0,\n",
       " 1617.495: 0,\n",
       " 1616.4375: 0,\n",
       " 34384.11: 0,\n",
       " 34386.145: 0,\n",
       " 1621.6958: 0,\n",
       " 34390.605: 0,\n",
       " 1623.3625: 0,\n",
       " 1624.0831: 0,\n",
       " 165463.27: 0,\n",
       " 34391.605: 0,\n",
       " 99931.29: 0,\n",
       " 1622.9034: 0,\n",
       " 1626.3383: 0,\n",
       " 1625.58: 0,\n",
       " 34397.11: 0,\n",
       " 1633.3616: 0,\n",
       " 1634.37: 0,\n",
       " 34403.387: 0,\n",
       " 1636.034: 0,\n",
       " 1633.9714: 0,\n",
       " 34414.85: 0,\n",
       " 1655.64: 0,\n",
       " 1657.12: 0,\n",
       " 1659.3717: 0,\n",
       " 34429.27: 0,\n",
       " 34430.383: 0,\n",
       " 1664.0: 0,\n",
       " 34438.45: 0,\n",
       " 1672.35: 0,\n",
       " 67214.555: 0,\n",
       " 1679.1425: 0,\n",
       " 34450.156: 0,\n",
       " 1682.0692: 0,\n",
       " 1685.1: 0,\n",
       " 1688.4313: 0,\n",
       " 34457.937999999995: 0,\n",
       " 1690.4183: 0,\n",
       " 1691.015: 0,\n",
       " 34461.81: 0,\n",
       " 1694.1167: 0,\n",
       " 1693.776: 0,\n",
       " 34461.316: 0,\n",
       " 67233.54: 0,\n",
       " 34469.0: 0,\n",
       " 1702.2937: 0,\n",
       " 34470.645: 0,\n",
       " 1705.88: 0,\n",
       " 1706.9695: 0,\n",
       " 1707.2156: 0,\n",
       " 1708.056: 0,\n",
       " 34476.18: 0,\n",
       " 1713.9353: 0,\n",
       " 1721.4563: 0,\n",
       " 1724.1: 0,\n",
       " 1725.12: 0,\n",
       " 1729.5886: 0,\n",
       " 1730.3514: 0,\n",
       " 1730.905: 0,\n",
       " 1732.8485: 0,\n",
       " 1733.055: 0,\n",
       " 34504.168: 0,\n",
       " 1737.24: 0,\n",
       " 1740.5914: 0,\n",
       " 1741.7349: 0,\n",
       " 1740.5885: 0,\n",
       " 34511.19: 0,\n",
       " 1743.1629999999998: 0,\n",
       " 34512.613: 0,\n",
       " 1743.9225: 0,\n",
       " 1748.9788: 0,\n",
       " 1756.9436: 0,\n",
       " 1762.938: 0,\n",
       " 67299.85: 0,\n",
       " 1767.36: 0,\n",
       " 1776.6187: 0,\n",
       " 165617.45: 0,\n",
       " 1779.82: 0,\n",
       " 34547.086: 0,\n",
       " 34549.492: 0,\n",
       " 1779.9729: 0,\n",
       " 34551.812000000005: 0,\n",
       " 1785.5405: 0,\n",
       " 67322.555: 0,\n",
       " 1787.2697: 0,\n",
       " 1794.8705: 0,\n",
       " 1796.799: 0,\n",
       " 34565.008: 0,\n",
       " 34566.637: 0,\n",
       " 34568.49: 0,\n",
       " 1803.8472: 0,\n",
       " 34572.707: 0,\n",
       " 1805.445: 0,\n",
       " 1803.5428: 0,\n",
       " 34576.504: 0,\n",
       " 1809.675: 0,\n",
       " 1810.914: 0,\n",
       " 1816.1375: 0,\n",
       " 34585.87: 0,\n",
       " 1820.6929: 0,\n",
       " 1820.41: 0,\n",
       " 1822.225: 0,\n",
       " 1824.2255: 0,\n",
       " 1824.87: 0,\n",
       " 1826.807: 0,\n",
       " 1828.8616: 0,\n",
       " 1828.2426: 0,\n",
       " 1830.4156: 0,\n",
       " 1836.8518: 0,\n",
       " 1837.78: 0,\n",
       " 1837.8846: 0,\n",
       " 263982.4: 0,\n",
       " 1840.0: 0,\n",
       " 34609.715: 0,\n",
       " 1837.6794: 0,\n",
       " 1847.0781: 0,\n",
       " 1848.1891: 0,\n",
       " 34621.254: 0,\n",
       " 1855.4158: 0,\n",
       " 1855.4486: 0,\n",
       " 1859.3625: 0,\n",
       " 1860.46: 0,\n",
       " 34628.49: 0,\n",
       " 34627.906: 0,\n",
       " 1861.4143: 0,\n",
       " 1864.385: 0,\n",
       " 165705.88: 0,\n",
       " 34637.637: 0,\n",
       " 34638.918: 0,\n",
       " 1876.2538: 0,\n",
       " 132949.19: 0,\n",
       " 1877.652: 0,\n",
       " 1876.8938: 0,\n",
       " 1880.56: 0,\n",
       " 1881.9492: 0,\n",
       " 1882.4841: 0,\n",
       " 1880.2483: 0,\n",
       " 1884.09: 0,\n",
       " 1885.7157: 0,\n",
       " 1888.9781: 0,\n",
       " 1889.2089: 0,\n",
       " 1892.8605: 0,\n",
       " 1894.9373: 0,\n",
       " 1894.804: 0,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prac_sec = {ev:ev for ev in list_of_prac}\n",
    "# phase = {ev:ev for ev in list_of_phase}\n",
    "# recent_r = {ev:ev for ev in list_of_recent_ratio}\n",
    "# assess = {ev:ev for ev in list_of_assess}\n",
    "# game_prac = {ev:ev for ev in list_of_game_prac}\n",
    "# total_time = {ev:ev for ev in list_of_total}\n",
    "# months = {ev:ev for ev in list_of_months}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    list_of_prac = list(set(train['practice_sec'].unique()).union(set(test['practice_sec'].unique())))\n",
    "    list_of_phase = list(set(train['time_by_phase_type'].unique()).union(set(test['time_by_phase_type'].unique())))\n",
    "    list_of_recent_ratio = list(set(train['recent_ratio'].unique()).union(set(test['recent_ratio'].unique())))\n",
    "    list_of_total = list(set(train['total_game_time'].unique()).union(set(test['total_game_time'].unique())))\n",
    "    list_of_months = list(set(train['months_played'].unique()).union(set(test['months_played'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n",
    "\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    \n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "    prac_sec: Dict[str, int] = {ev:ev for ev in list_of_prac}\n",
    "    phase: Dict[str, int] = {ev:ev for ev in list_of_phase}\n",
    "    recent_r: Dict[str, int] = {ev:ev for ev in list_of_recent_ratio}\n",
    "    total_time: Dict[str, int] = {ev:ev for ev in list_of_total}\n",
    "    months: Dict[str, int] = {ev:ev for ev in list_of_months}\n",
    "    \n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "                    \n",
    "            \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(prac_sec.copy())\n",
    "            features.update(phase.copy())\n",
    "            features.update(recent_r.copy())\n",
    "            features.update(total_time.copy())\n",
    "            features.update(months.copy())\n",
    "            \n",
    "            \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments\n",
    "\n",
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals\n",
    "\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n",
    "# train.to_csv('train_encoded.csv')\n",
    "# test.to_csv('test_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reduce_train, reduce_test):\n",
    "    for df in [reduce_train, reduce_test]:\n",
    "        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n",
    "        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "        #df['installation_duration_std'] = df.groupby(['installation_id'])['duration_mean'].transform('std')\n",
    "        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "        \n",
    "        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n",
    "                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n",
    "                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n",
    "        \n",
    "        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "        #df['installation_event_code_count_std'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('std')\n",
    "        \n",
    "    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "    features = [x for x in features if x not in ['accuracy_group', 'installation_id']] + ['acc_' + title for title in assess_titles]\n",
    "   \n",
    "    return reduce_train, reduce_test, features\n",
    "# call feature engineering function\n",
    "reduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':2000,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'subsample': 0.75,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.04,\n",
    "            'feature_fraction': 0.9,\n",
    "         'max_depth': 15,\n",
    "            'lambda_l1': 1,  \n",
    "            'lambda_l2': 1,\n",
    "            'verbose': 100,\n",
    "            'early_stopping_rounds': 100, 'eval_metric': 'cappa'\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reduce_train['accuracy_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = GroupKFold(n_splits=n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['game_session', 'installation_id', 'timestamp', 'accuracy_group', 'timestampDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = MainTransformer()\n",
    "ft = FeatureTransformer()\n",
    "transformers = {'ft': ft}\n",
    "regressor_model1 = RegressorModel(model_wrapper=LGBWrapper_regr())\n",
    "regressor_model1.fit(X=reduce_train, y=y, folds=folds, params=params, preprocesser=mt, transformers=transformers,\n",
    "                    eval_metric='cappa', cols_to_drop=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "        return -qwk(y, X_p)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pr1 = regressor_model1.predict(reduce_train)\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(pr1.reshape(-1,), y)\n",
    "coefficients = optR.coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_preds = optR.predict(pr1.reshape(-1, ), coefficients)\n",
    "qwk(y, opt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = regressor_model1.predict(reduce_test)\n",
    "pr1[pr1 <= 1.12232214] = 0\n",
    "pr1[np.where(np.logical_and(pr1 > 1.12232214, pr1 <= 1.73925866))] = 1\n",
    "pr1[np.where(np.logical_and(pr1 > 1.73925866, pr1 <= 2.22506454))] = 2\n",
    "pr1[pr1 > 2.22506454] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['accuracy_group'] = pr1.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
